1.  （1）机器学习是一种通过数据集产生算法的算法
    （2）深度学习是机器学习的一个子集，深度学习不需要自己设计特征并可以处理无结构的数据（图片音频等）
2.  监督学习的数据集有标签，无监督学习的则没有
3.  （1）偏导数是函数关于其中一个变量的导数
    （2）链式法则指一个函数表达式分解为的计算图中一条链中每一步的偏导数相乘可以得到这条链的偏导数，一个变量到原函数的每条链的偏导数相加可以得到原函数对于原始变量的偏导数
    （3）梯度就是一个向量，它的每一维都是原函数对一个变量的偏导数
    （4）矩阵乘法即一个n x m的矩阵和一个 m x p的矩阵相乘得到一个n x p的矩阵
     (5)偏导数可以代表一个变量对函数值的影响程度，梯度综合了这些影响，将自己变为一个影响函数值时唯一需要被考虑的变量，链式法则提供了操作这个变量的方法（反向传播），矩阵乘法由于乘后大小的改变，可以通过构造一个矩阵与原矩阵相乘，使原矩阵和结果形成映射，可以实现特征的降维
4.  （1）损失函数描述了模型结果和正确答案的偏离程度
    （2）梯度下降即按照梯度所决定的比例按一定的学习率不断修改参数并计算损失
    （3）借助链式法则可以计算出梯度，然后就可以梯度下降了
5.  （1）样本是数据集的一个单位
    （2）特征是数据的有效部分，需要被机器学习算法识别记录和学习的对象，应当是结构化的数据
    （3）因为复数层线性隐藏层可以被化简为一层，而激活函数可以引入非线性增加复杂度
6.  线性回归就是找到一个线性函数拟合目标的过程，逻辑回归就是把自变量输入到线性函数内得到的值再映射到不同的类别中。逻辑回归可以看作是线性回归的结果加上一层映射，但是他们选择的损失函数可能不一样。
7.  训练集用于改变模型中的参数，验证集用于在早期每个epoch结束后评估模型性能并试着调整超参数，测试集用于最后的评价。