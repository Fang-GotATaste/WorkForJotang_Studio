1.  anaconda的问题(?)：安装tensorflow在虚拟环境中，在ide中的终端启动了虚拟环境，并在此终端中成功打印了tensor的版本号，但是在运行文件时却有“无法解析导入tensorflow”的报错，而chatgpt说ide有对虚拟环境的支持并且应当会自动切换python解释器，在ide的终端中启动应当属于这种状况。没搞明白。现在直接在虚拟机系统环境中安装了tf，但是在终端中执行的打印版本号程序时却出现了no module named tensorflow问题,是的，情况反转了，在命令行中报错，在ide的一键执行却能成功（当然有2中的报错），我不确定这种关系是否有什么张力
2.  tensorflow的问题：出现cuDNN cuFFT cuBLAS 的Unable to register xxx factory 错误，并且在github上找到了最近的issue：https://github.com/tensorflow/tensorflow/issues/62075（仍然是open状态），说明此问题不是个例，并且cuDNN和cuda与tensorflow之间的包含关系实在令人感到混乱（我分别用包管理器安装了cuda-toolkit和tensorflow，并被告知的是cuDNN已经被包含在tf或者cuda里，而我看到的安装可选项中还有tensor-gpu和tensor[and cuda]）
    在出现这些报错的时候我依然调用函数并成功打印出版本号，但是如果试图去运行MNIST的训练代码就会出现其他的报错无法完成：TF-TRT Warning: Could not find TensorRT，按照chatgpt的说法可能是需要特定版本的tf（我第一次在虚拟环境中尝试的是1.2,在系统环境中分别尝试过1.2和2.14），否则可能需要自己下载TRT并用Bazel重新构建（大概是说编译？）tf（包括还有一条information级别的信息说机器支持xx指令集，请重构tf来应用），这超出了我目前要关心的范围（其实说起来感觉大体就是那些框架和特定库之间的支持关系问题，TRT是跟显卡有关的？也许有一个“切换到纯cpu模式”可以暂时先把燃眉之急解了）
3.  虚拟机的问题：tf中的函数结果表明我没有可用的gpu，虽然vmware应该默认有显卡虚拟化，但是也许没法被cuda使用？
    目前查找到的显卡设备只有一个VGA compatible controller，也许我的geforce显卡没有被虚拟化进来？没搞明白。日后直接使用双系统应该可以满足学习要求。不过这比起2来说目前不是什么值得关注的问题。后来在docker的pytorch容器里我成功使用了显卡。


4.  此时已经来到了10月23号的晚上9点，我决定暂时放弃一切对环境配置的理解的尝试，试着用docker来进行。
    下载了一个tensorflow的image，尝试在desktop中启动，点击启动按钮没反应，status一直是exit（0）
    尝试用那个菜单栏里的dev env，在那个容器的下方新建了一个开发环境，在vscode里直接打开了，如果能用vscode，确实之前预期的只能用shell就显得很麻烦。但是这原来是一个完全空的开发环境，完全没有任何东西，不是我想要的。
    启动失败是没打开hyper-v？docker对这个竟然也完全没有提示。->打开hyper-v后也还是一样的结果。
    试图在命令行中操作，试图给run加上--privileged标签，但是都没有用。
    我参照一个教程给run命令加上-t标签，成功运行了docker容器。（docker容器一旦没有前台进程就会退出并返回0，-t为分配一个伪终端给这个容器，即一个长期运行的进程）现在容器里有一个bash，将py文件传到容器里，我可以用vim编辑并解释运行。


5.  现在终于来到了代码测试阶段。我将在docker的命令行界面中运行使用tf的教程bp网络代码，然后依然在vmware中尝试理解和运行用pytorch构建的cnn网络。
    我在容器中运行了教程的py文件，没有输出，只有一个目前无关紧要的I级信息，跟之前在vmware里见过的一样，不过没有报错。但是输出呢？
    原来是它代码的运行部分跟类的定义分开了，原作者要求用独立的运行代码来调用这里定义的库。我把它们合并到一起。
    我没法找到教程使用的mnist_loader包，我把mnist的导入方式改为使用python-mnist包——>我不确定MNIST包的使用方法能否无缝切入原来的语法，改用tf自带的mnist
    教程的代码经过这个库的更改不能直接运行。在shuffle数据处报了不能更改元组的错，但是按chatgpt的说法，mnist.load_data()返回的应该是numpy数组->澄清：返回的是两个包含两个numpy数组即数据和标签的元组。那么我尝试在导入的时候把它显式地拆开为数据和标签并且替换到每一个使用了trainingdata等变量的地方去。——>直接替换似乎会导致未定义问题，使用list（zip（））打包为列表。错误解除。

    还有一些我怀疑是代码本身的问题：报错点乘的矩阵形状不合法。观察可知，权重矩阵需要是一个能和图像矩阵点乘的矩阵（线性模型weight x data + bias），至少代码里是直接和图像数据本身乘。图像数据是一个28x28的方阵，而程序教程本身给出的784个输入节点，30个隐藏层节点，第一层权重的矩阵就是30x784，要怎么跟图像数据相乘呢？
    我更改了输入节点数量为28，形成28x30的矩阵，程序运行成功，但是每一个epoch的准确率都是980/10000（至少随机性还可以，初始正确率为十分之一），没有上升。（后面见过了那种波动，突然意识到这个不变是很奇怪的东西）
    我意识到784=28x28，也许他的意思是把图像矩阵变成一个1x784的矩阵，我用reshape尝试了一下,每个epoch的学习开始有变动了：
    不仅每次上升小，而且很小的值就开始下降，后面就只是波动，基本都脱不出十分之一的范围
    把学习率改成0.001，0.01，又改回来，都无改变
    看到sigmiod函数有溢出情况，修改为网上的防溢出版本，不再警告，但是无改善。再修改学习率，再改权重矩阵形状，都不能改善。我认为是模型本身存在缺陷。
    图片：![{输出结果记录}.png](https://s2.loli.net/2023/10/24/duJA6qHCcI1U4mM.png)
    还有一个感想就是tensorflow相比pytorch的易用性感觉真的差了好多，再者就是，这个源代码里真的用到了tensorflow的东西吗？


