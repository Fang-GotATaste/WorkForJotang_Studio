1.  anaconda的问题(?)：安装tensorflow在虚拟环境中，在ide中的终端启动了虚拟环境，并在此终端中成功打印了tensor的版本号，但是在运行文件时却有“无法解析导入        tensorflow”的报错，而chatgpt说ide有对虚拟环境的支持并且应当会自动切换python解释器，在ide的终端中启动应当属于这种状况。没搞明白。现在直接在虚拟机系统环境中安装了tf，但是在终端中执行的打印版本号程序时却出现了no module named tensorflow问题,是的，情况反转了，在命令行中报错，在ide的一键执行却能成功（当然有2中的报错），我不确定这种关系是否有什么张力
2.  tensorflow的问题：出现cuDNN cuFFT cuBLAS 的Unable to register xxx factory 错误，并且在github上找到了最近的issue：https://github.com/tensorflow/tensorflow/issues/62075（仍然是open状态），说明此问题不是个例，并且cuDNN和cuda与tensorflow之间的包含关系实在令人感到混乱（我分别用包管理器安装了cuda-toolkit和tensorflow，并被告知的是cuDNN已经被包含在tf或者cuda里，而我看到的安装可选项中还有tensor-gpu和tensor[and cuda]）
    在出现这些报错的时候我依然调用函数并成功打印出版本号，但是如果试图去运行MNIST的训练代码就会出现其他的报错无法完成：TF-TRT Warning: Could not find TensorRT，按照chatgpt的说法可能是需要特定版本的tf（我第一次在虚拟环境中尝试的是1.2,在系统环境中分别尝试过1.2和2.14），否则可能需要自己下载TRT并用Bazel重新构建（大概是说编译？）tf（包括还有一条information级别的信息说机器支持xx指令集，请重构tf来应用），这超出了我目前要关心的范围（其实说起来感觉大体就是那些框架和特定库之间的支持关系问题，TRT是跟显卡有关的？也许有一个“切换到纯cpu模式”可以暂时先把燃眉之急解了）
3.  虚拟机的问题：tf中的函数结果表明我没有可用的gpu，虽然vmware应该默认有显卡虚拟化，但是也许没法被cuda使用？
    目前查找到的显卡设备只有一个VGA compatible controller，也许我的geforce显卡没有被虚拟化进来？没搞明白。日后直接使用双系统应该可以满足学习要求。不过这比起2来说目前不是什么值得关注的问题。


4.  此时已经来到了10月23号的晚上9点，我决定暂时放弃一切对环境配置的理解的尝试，试着用docker来进行。